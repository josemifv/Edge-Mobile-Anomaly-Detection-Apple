Edge-Mobile Anomaly Detection Apple - Project Context
====================================================

1. PROJECT OVERVIEW
==================

Project: Mobile Network Anomaly Detection Pipeline Optimized for Apple Silicon
Purpose: Academic research for CMMSE 2025 conference submission
Repository: https://github.com/josemifv/Edge-Mobile-Anomaly-Detection-Apple.git
Branch: cmmse2025 (current development branch)
Python Version: 3.13.2 (managed with uv tool)

Academic Focus:
- Enhanced mobile network anomaly detection pipeline
- Hardware optimization for Apple Silicon (M-series processors) 
- OSP (Orthogonal Subspace Projection) based anomaly detection
- Research-grade implementation with reproducible results

2. CURRENT REPOSITORY STRUCTURE
===============================

Edge-Mobile-Anomaly-Detection-Apple/
├── .git/                          # Git version control
├── .gitignore                     # Git ignore patterns
├── .python-version                # Python 3.13 specification
├── .venv/                         # Virtual environment (uv-managed)
├── LICENSE                        # MIT License (José Miguel Franco-Valiente)
├── README.md                      # Complete project documentation
├── requirements.txt               # Python dependencies
├── backup/                        # Backup directory (git-ignored)
├── data/                          # Data storage
│   ├── raw@ -> ../../datasets/milan_telecom/raw  # Symlink to raw data
│   └── processed/                 # Processed data files
│       ├── ingested_data.parquet     # Stage 1 output (4.4GB, 319.9M rows)
│       ├── preprocessed_data.parquet # Stage 2 output (2.0GB, 89.2M rows)
│       └── reference_weeks.parquet   # Stage 3 output (479KB, 39.4K refs)
├── results/                       # Analysis outputs and results
│   ├── anomalies.parquet             # Standard anomaly detection results
│   ├── full_individual_anomalies.parquet  # Individual anomaly records (148MB)
│   ├── severe_anomalies_top_*.csv    # Severity analysis reports
│   ├── figures/                      # Visualization outputs
│   ├── benchmarks/                   # Performance benchmark results
│   └── data/                         # Micro test results by configuration
└── scripts/                       # Core pipeline implementation (11 scripts)
    ├── 01_data_ingestion.py             # Stage 1: Data loading & preprocessing
    ├── 02_data_preprocessing.py         # Stage 2: Aggregation & validation
    ├── 03_week_selection.py             # Stage 3: Reference week selection
    ├── 04_anomaly_detection_individual.py   # Stage 4: Individual anomaly detection
    ├── 05_analyze_anomalies.py          # Stage 5: Comprehensive anomaly analysis
    ├── 06_generate_anomaly_map.py       # Geographic anomaly visualization
    ├── 07_plot_extreme_cell_timeline.py # Extreme cell timeline analysis
    ├── analyze_severe_anomalies.py      # Severity analysis tools
    ├── benchmark_parameter_sweep.py     # Comprehensive parameter optimization
    ├── benchmark_micro_test.py          # Quick system validation
    └── run_pipeline.py                  # Complete 5-stage pipeline orchestrator

3. CORE PIPELINE ARCHITECTURE (5 STAGES - REFACTORED)
====================================================

Stage 1: Data Ingestion (01_data_ingestion.py)
- Input: Raw .txt files from Milano Telecom dataset
- Processing: Parallel file loading optimized for Apple Silicon
- Features: Timestamp conversion, column standardization, data type optimization
- Output: ingested_data.parquet (319.9M rows, 4.4GB)
- Performance: 1.77M rows/second (181.02s execution)

Stage 2: Data Preprocessing (02_data_preprocessing.py)
- Input: Ingested data from Stage 1
- Processing: Cell-wise aggregation, directional column merging, validation
- Features: SMS/call consolidation, quality checks, 72% data compression
- Output: preprocessed_data.parquet (89.2M rows, 2.0GB)
- Performance: 564K rows/second (159.17s execution)

Stage 3: Reference Week Selection (03_week_selection.py)
- Input: Preprocessed data from Stage 2
- Processing: MAD (Median Absolute Deviation) analysis for normal week identification
- Features: ISO week numbering, statistical outlier detection, configurable thresholds
- Output: reference_weeks.parquet (39.4K reference weeks)
- Performance: 795K rows/second (112.27s execution)

Stage 4: Individual Anomaly Detection (04_anomaly_detection_individual.py) [POLARS OPTIMIZED]
- Input: Preprocessed data + reference weeks from Stages 2 & 3
- Processing: OSP with individual anomaly record capture using Polars + NumPy
- Features: Vectorized operations, parallel processing, float32 optimization
- Output: individual_anomalies.parquet (individual anomaly records with full details)
- Performance: 783K samples/second (114s for 89.2M samples, 5.6M anomalies detected)

Stage 5: Comprehensive Anomaly Analysis (05_analyze_anomalies.py) [NEW]
- Input: Individual anomaly records from Stage 4
- Processing: Statistical analysis, pattern identification, visualization generation
- Features: Temporal analysis, severity ranking, cell-level patterns, report generation
- Output: Analysis reports, visualizations, and research-grade insights
- Performance: Fast analysis of detected anomalies

4. ALGORITHM IMPLEMENTATION
==========================

OSP (Orthogonal Subspace Projection) Anomaly Detection:
- Mathematical foundation: SVD decomposition X = UΣV^T
- Normal subspace projection with reconstruction error calculation
- Anomaly scoring: ||residuals||_2 compared to threshold
- Per-cell training using reference weeks from Stage 3
- Configurable parameters:
  * n_components: SVD dimensions (default: 3)
  * anomaly_threshold: Standard deviation multiplier (default: 2.0)
  * standardize: Feature standardization (default: True)

Enhanced Individual Tracking (04_anomaly_detection_osp_detailed.py):
- Individual anomaly record capture with timestamps
- Severity scoring: (anomaly_score - training_mean) / training_std
- Traffic feature preservation for analysis
- Excess factor calculation (threshold multiples)

5. PERFORMANCE ACHIEVEMENTS (Apple Silicon M4 Pro)
==================================================

Dataset: Milano Telecom (62 files, 319.9M rows, Nov 2013 - Jan 2014)

Pipeline Performance:
- Stage 1: 181.02s | 1.77M rows/sec | 319.9M → 319.9M rows
- Stage 2: 159.17s | 564K rows/sec | 319.9M → 89.2M rows (72% compression)
- Stage 3: 112.27s | 795K rows/sec | 39.4K reference weeks selected
- Stage 4: 469.97s | 190K samples/sec | 5.65M anomalies (6.33% rate)
- Total: 922.43s (15.37 minutes) | 347K rows/sec overall

Key Metrics:
- Success rate: 100% (10,000/10,000 cells processed)
- Data compression: 72% through aggregation
- Anomaly detection rate: 6.33% average across all cells
- Memory efficiency: 5.6GB peak usage
- Reference weeks: 39.4K selected (≈4 per cell average)

Anomaly Severity Analysis:
- Severity range: 2.0σ to 5,717σ (standard deviations above normal)
- Most severe cell: 5240 (multiple extreme anomalies)
- Peak anomaly patterns: Night hours (01:00-02:00), weekdays
- Traffic characteristics: High call volumes without proportional SMS/internet

6. APPLE SILICON OPTIMIZATIONS
==============================

Hardware Acceleration:
- Native ARM64 compilation (aarch64 architecture)
- PyTorch MPS (Metal Performance Shaders) support enabled
- Automatic CPU core detection and utilization
- Optimized multiprocessing for M-series processors

Software Optimizations:
- NumPy/SciPy ARM64 optimized versions
- scikit-learn Apple Silicon compilation
- Parallel processing strategies for file I/O and computation
- Memory-efficient data structures and operations

Configuration:
- Default workers: Auto-detected (8-14 for M-series)
- Virtual environment: Python 3.13.2 with uv package manager
- Dependencies: All Apple Silicon native packages

7. DEVELOPMENT TOOLS & ENVIRONMENT
==================================

Python Environment:
- Python 3.13.2 (specified in .python-version)
- Package manager: uv 0.6.14 (Astral's fast tool)
- Virtual environment: .venv/ (properly isolated)
- Dependencies: requirements.txt (traditional approach for academic simplicity)

Core Dependencies:
- pandas ≥2.3.0 (data processing)
- numpy ≥2.2.6 (numerical computing)
- pyarrow ≥20.0.0 (parquet I/O)
- scikit-learn ≥1.7.0 (machine learning)
- torch ≥2.2.0 (MPS support for Apple Silicon)
- matplotlib ≥3.10.3, seaborn ≥0.13.2 (visualization)
- psutil ≥7.0.0 (system monitoring)

Development Tools:
- pytest ≥8.0.0 (testing framework)
- black ≥24.1.0 (code formatting)
- isort ≥5.13.0 (import sorting)

8. ACADEMIC RESEARCH FEATURES
=============================

CMMSE 2025 Conference Focus:
- Clean, documented code structure for academic publication
- Reproducible results with parameter control
- Comprehensive performance benchmarking
- Individual anomaly analysis capabilities

Research Tools:
- Parameter sweep framework (benchmark_parameter_sweep.py)
- Quick validation testing (benchmark_micro_test.py)
- Severity analysis with visualizations (analyze_severe_anomalies.py)
- Individual anomaly tracking for case studies

Documentation:
- Complete README with usage examples
- Inline code documentation and academic comments
- Performance results and configuration tables
- Research-grade implementation standards

9. CURRENT PROJECT STATUS
=========================

Development Branch: cmmse2025
Last Commit: 65f792c - "feat: Optimize Stage 4 with Polars migration and performance improvements"

Refactored Components:
✅ REFACTORED: 5-stage pipeline architecture (Stage 4 + new Stage 5)
✅ NEW: Individual anomaly detection without aggregation (Stage 4)
✅ NEW: Comprehensive anomaly analysis framework (Stage 5)
✅ NEW: Geographic anomaly visualization with Milano grid (Stage 6)
✅ NEW: Extreme cell timeline analysis (Stage 7)
✅ SIMPLIFIED: Single pipeline runner (run_pipeline.py) for 5-stage execution
✅ Apple Silicon optimization verified and documented
✅ Complete dataset processing (100% success rate)
✅ Enhanced individual anomaly analysis capabilities
✅ Interactive maps with percentile-based classification
✅ Comprehensive timeline visualizations for extreme cells
✅ Comprehensive benchmarking tools
✅ Academic documentation for CMMSE 2025
✅ Clean repository structure with minimal dependencies
✅ CODE REVIEW FIXES: All improvements from codex_review.md implemented
  • Fixed warnings filtering to be more specific and scoped
  • Updated README.md to reflect 5-stage pipeline architecture
  • Fixed ranking logic in 03_week_selection.py for clarity
  • Optimized CSV reading performance in 01_data_ingestion.py
  • Fixed hardcoded cell ID limits in 06_generate_anomaly_map.py
  • Standardized timing functions to use time.perf_counter()
  • Fixed Pool arguments to use explicit processes= parameter
  • Requirements.txt already had missing dependencies added

Refactoring Benefits:
✅ Separation of detection and analysis concerns
✅ Individual anomaly records for detailed research
✅ Flexible analysis capabilities for different research questions
✅ Better suited for academic publication and case studies

Testing Status:
✅ End-to-end pipeline verification completed
✅ Performance benchmarking on full dataset
✅ Individual anomaly analysis validated
✅ Micro testing framework operational
✅ NEW: 5-stage refactored pipeline successfully tested
✅ COMPLETE: Full dataset 5-stage pipeline execution (10,000 cells)
✅ CLEAN: Repository cleaned of all generated files (ready for production)

Full Pipeline Test Results (Complete Dataset - 10,000 cells):
- Stage 1: 81.49s | 3.96M rows/sec | 319.9M rows processed
- Stage 2: 107.95s | 829K rows/sec | 89.2M rows output (72% compression)
- Stage 3: 7.33s | Reference week selection for 10,000 cells (39.5K weeks)
- Stage 4: ~6-8 minutes | 10,000 cells processed | 4.86M individual anomalies detected
- Stage 5: 10.58s | Complete analysis and visualization generation
- Total: ~15-17 minutes for complete dataset
- Anomaly rate: 5.45% | Severity range: 2.0σ to 7,791σ | Peak times: 16:00-17:00

Validated Analysis Results:
- Total anomalies detected: 4,864,815
- Unique cells with anomalies: 10,000 (100% coverage)
- Date range: 2013-10-31 to 2014-01-01
- Peak anomaly times: Rush hours (16:00-17:00) and morning hours (07:00-11:00)
- Weekday bias: Tuesday/Wednesday peak, weekend reduced activity
- Top anomalous cells: 4472 (4,524 anomalies), 4772 (4,521 anomalies)
- Generated outputs: Summary report, severity distribution plot, hourly pattern visualization

Repository Health:
✅ Clean commit history with academic focus
✅ Proper dependency management with uv
✅ Data directories excluded from version control
✅ Backup system implemented
✅ Documentation complete and current

10. USAGE EXAMPLES
==================

Individual Stage Execution:
```bash
# Stage 1: Data Ingestion
uv run scripts/01_data_ingestion.py data/raw/ --output_path data/processed/ingested_data.parquet

# Stage 2: Data Preprocessing  
uv run scripts/02_data_preprocessing.py data/processed/ingested_data.parquet --output_path data/processed/preprocessed_data.parquet

# Stage 3: Reference Week Selection
uv run scripts/03_week_selection.py data/processed/preprocessed_data.parquet --output_path data/processed/reference_weeks.parquet

# Stage 4: Individual Anomaly Detection
uv run scripts/04_anomaly_detection_individual.py data/processed/preprocessed_data.parquet data/processed/reference_weeks.parquet --output_path results/individual_anomalies.parquet
```

Complete Pipeline:
```bash
# Run complete 5-stage pipeline
uv run scripts/run_pipeline.py data/raw/ --output_dir results/

# With custom parameters
uv run scripts/run_pipeline.py data/raw/ --output_dir results/ --n_components 5 --anomaly_threshold 2.5 --preview
```

Enhanced Analysis:
```bash
# Generate comprehensive analysis
uv run scripts/05_analyze_anomalies.py results/individual_anomalies.parquet --output_dir results/

# Analyze severe anomalies
uv run scripts/analyze_severe_anomalies.py results/individual_anomalies.parquet --top_n 20 --generate_plots --export_report
```

11. NEXT RESEARCH DIRECTIONS
============================

Potential Extensions:
- Additional anomaly detection algorithms (Isolation Forest, Autoencoders)
- Time series feature engineering enhancements
- Spatial correlation analysis between cells
- Real-time anomaly detection capabilities
- Comparative studies with other hardware architectures

Academic Applications:
- Network incident investigation frameworks
- Capacity planning optimization
- Security monitoring for telecom networks
- Quality of service enhancement strategies

Publication Ready:
- Code structure optimized for academic review
- Comprehensive documentation and examples
- Reproducible results with clear methodology
- Performance benchmarks for Apple Silicon architecture

==========================================
Status: ✅ COMPLETE - CMMSE 2025 Ready
Last Updated: June 21, 2025
==========================================
