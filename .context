Contexto del Proyecto: Pipeline de Detecci√≥n de Anomal√≠as en Datos Telecom
1. Visi√≥n General del Proyecto

El objetivo principal es desarrollar un pipeline en Python para detectar anomal√≠as en el dataset de telecomunicaciones de Mil√°n. Una meta secundaria es evaluar la idoneidad de las m√°quinas con SoC de Apple para este tipo de tareas de Machine Learning, centr√°ndose en la potencia y el consumo energ√©tico.
2. Resumen del Script Actual: telecom_data_loader_py

El script actual (referenciado en el Canvas como telecom_data_loader_py) se enfoca en la carga y preprocesamiento inicial de los datos de telecomunicaciones desde archivos CSV.

    Prop√≥sito Principal: Leer archivos CSV con un formato espec√≠fico (delimitado por espacios, n√∫mero variable de columnas de actividad) y convertirlos en DataFrames de Pandas utilizables.

    Funcionalidades Clave:

        Carga de un √∫nico archivo CSV.

        Procesamiento de todos los archivos CSV dentro de un directorio especificado.

        Manejo de lectura por trozos (chunk_size) para archivos grandes.

        Conversi√≥n de timestamps de milisegundos a objetos datetime de Pandas.

        Manejo b√°sico de errores durante la carga.

        Parametrizaci√≥n mediante argumentos de l√≠nea de comandos (argparse) para controlar el comportamiento.

    Formato de Entrada Esperado (CSV):

        Delimitador: M√∫ltiples espacios en blanco (delim_whitespace=True).

        Sin encabezado (header=None).

        Columnas (en orden):

            square_id (entero)

            timestamp_ms (entero, timestamp Unix en milisegundos)

            country_code (entero)

            sms_in (decimal, opcional)

            sms_out (decimal, opcional)

            call_in (decimal, opcional)

            call_out (decimal, opcional)

            internet_activity (decimal, opcional)

        Las columnas de actividad (4-8) pueden no estar presentes en todas las filas; se manejan como NaN.

    Salida del Script:

        Una lista de DataFrames de Pandas (uno por cada archivo CSV procesado exitosamente).

        Mensajes en la consola indicando el progreso, errores y tiempos de ejecuci√≥n.

        Opcionalmente, un resumen del DataFrame resultante (o combinado) si se usa --output_summary.

    Variables de Inter√©s para Pruebas de Rendimiento (Parametrizadas):

        input_path: Ruta al archivo/directorio de entrada.

        chunk_size: Tama√±o de los trozos para la lectura de CSV.

        convert_timestamp: Booleano para activar/desactivar la conversi√≥n de timestamp.

        reorder_cols: Booleano para activar/desactivar el reordenamiento de columnas.

    Constantes Clave:

        COLUMN_NAMES: Lista que define los nombres esperados para las columnas del CSV.

3. Estructuras de Datos Clave

    DataFrame de Entrada (crudo, por archivo): Estructura seg√∫n COLUMN_NAMES.

    DataFrame de Salida (por archivo procesado):

        square_id: Int64

        country_code: Int64

        sms_in, sms_out, call_in, call_out, internet_activity: float64 (con NaNs donde falten datos)

        timestamp: datetime64[ns] (si convert_timestamp est√° activo)

4. Estado Actual del C√≥digo

    COMPLETADO: El script 01_data_ingestion.py est√° funcional para la carga y el preprocesamiento b√°sico seg√∫n lo descrito.

    COMPLETADO: El script 02_data_preprocessing.py implementa la consolidaci√≥n, agregaci√≥n y validaci√≥n de datos.

    COMPLETADO: El script 03_week_selection.py implementa la selecci√≥n de semanas de referencia usando an√°lisis MAD.

    Se ha eliminado el c√≥digo de simulaci√≥n de datos.

    Todos los scripts est√°n parametrizados para facilitar la ejecuci√≥n y las pruebas.

El pipeline actual incluye:
        - Carga paralela de archivos (14 procesos en Apple Silicon)
        - Conversi√≥n de timestamps de milisegundos a datetime
        - Eliminaci√≥n de columna country_code
        - Agregaci√≥n por cell_id y timestamp
        - Fusi√≥n de columnas direccionales:
          * sms_total = sms_in + sms_out
          * calls_total = call_in + call_out
          * Eliminaci√≥n de columnas direccionales individuales
        - Consolidaci√≥n en un DataFrame √∫nico
        - Validaci√≥n completa (duplicados y valores nulos)
        - Soporte para salida en CSV y Parquet
        - Reportes de rendimiento detallados

    Rendimiento Conseguido (Apple Silicon):
        - 319,896,289 filas procesadas en ingesta inicial (48.67s)
        - 89,245,318 filas finales despu√©s de preprocesamiento (82.56s)
        - Velocidad: 1,080,928 filas/segundo en preprocesamiento
        - Compresi√≥n: 72% reducci√≥n de filas por agregaci√≥n
        - Archivo final: 2.9GB en formato Parquet
        - Rango temporal: Nov 2013 - Ene 2014 (62 d√≠as)
        - 10,000 celdas √∫nicas en el grid de Mil√°n

    Rendimiento Etapa 03 (Selecci√≥n de Semanas):
        - 40,000 semanas de referencia seleccionadas (4 por celda)
        - Tiempo de procesamiento: 72.47s
        - Throughput: 137 celdas/segundo
        - Uso de memoria: 3.5GB pico
        - An√°lisis MAD: 599,940 mediciones computadas
        - Cobertura semanas normales: 67.5% promedio
        - Configuraci√≥n √≥ptima: 3 semanas, umbral MAD 1.5

5. Estado Actual del Pipeline

    Pipeline Completo Hasta Etapa 04:
        ‚úÖ Etapa 01: Ingesta de datos (48.67s)
        ‚úÖ Etapa 02: Preprocesamiento (82.56s) 
        ‚úÖ Etapa 03: Selecci√≥n de semanas (72.47s)
        ‚úÖ Etapa 04: Detecci√≥n de anomal√≠as OSP (40.47s dataset completo)
        - Tiempo total pipeline: 244.17s (203.70s + 40.47s detecci√≥n completa)
        - Benchmarking automatizado implementado para todas las etapas
        - Reportes de rendimiento completos
        - Pipeline completo funcional de extremo a extremo

6. Estado de Desarrollo del Pipeline

    COMPLETADO - Pipeline Funcional de Extremo a Extremo:
    
        ‚úÖ Etapa 01: Ingesta de Datos
        - M√∫ltiples niveles de optimizaci√≥n (0-3)
        - Procesamiento paralelo para Apple Silicon
        - Benchmarking automatizado
        
        ‚úÖ Etapa 02: Preprocesamiento de Datos  
        - Agregaci√≥n y consolidaci√≥n
        - Validaci√≥n completa de integridad
        - Optimizaci√≥n de memoria
        
        ‚úÖ Etapa 03: Selecci√≥n de Semanas de Referencia
        - An√°lisis MAD para identificar semanas normales
        - 40,000 semanas seleccionadas (4 por celda)
        - Framework de benchmarking param√©trico
        
        ‚úÖ Etapa 04: Detecci√≥n de Anomal√≠as OSP
        - Algoritmo OSP con modelado SVD per-celda
        - Configuraci√≥n √≥ptima determinada mediante benchmarking
        - Escalabilidad DEMOSTRADA en dataset completo (89M muestras)
        - Framework de benchmarking completo

7. Pr√≥ximos Pasos de Desarrollo (Prioridades)

    Optimizaci√≥n del Almacenamiento/Organizaci√≥n de Datos:

        Tarea: Implementar una funcionalidad (posiblemente un nuevo script o una extensi√≥n del actual) para reorganizar los datos cargados y almacenarlos por square_id.

        Objetivo: Facilitar el acceso r√°pido a los datos de una celda espec√≠fica para la detecci√≥n de anomal√≠as aislada.

        Consideraciones:

            Formato de salida: Considerar Parquet o Feather en lugar de CSV para eficiencia.

            Estructura de salida: Un archivo por square_id o particionamiento nativo de Parquet.

            Manejo de memoria si el dataset combinado es muy grande antes de la reorganizaci√≥n.

            A√±adir argumentos al script para controlar esta nueva funcionalidad (ej. --output_cell_data_path /ruta/, --output_format parquet).

        M√©tricas de Rendimiento: Medir el tiempo de esta etapa de reorganizaci√≥n y el beneficio en la velocidad de acceso posterior.

    Ingenier√≠a de Caracter√≠sticas (Feature Engineering):

        Tarea: A√±adir una nueva secci√≥n/script para crear caracter√≠sticas relevantes para la detecci√≥n de anomal√≠as a partir de los datos preprocesados.

        Ejemplos:

            Caracter√≠sticas temporales m√°s avanzadas (ej. parte del d√≠a, si es festivo - requerir√≠a datos externos).

            Caracter√≠sticas de lag (valores de actividad en t-1, t-2, etc.).

            Estad√≠sticas m√≥viles (media, std dev de actividad en ventanas de tiempo).

            Diferencias respecto a patrones hist√≥ricos de la misma celda.

        Parametrizaci√≥n: Permitir seleccionar qu√© caracter√≠sticas generar.

    Implementaci√≥n de Algoritmos de Detecci√≥n de Anomal√≠as (COMPLETADO - ETAPA 04):

        COMPLETADO: El script 04_anomaly_detection_osp.py implementa detecci√≥n de anomal√≠as OSP.

        Algoritmos Implementados:

            ‚úÖ 1. Algoritmos basados en Proyecciones Ortogonales (OSP) - COMPLETADO
               - Implementado usando las semanas de referencia seleccionadas
               - Modelado SVD per-celda con par√°metros configurables
               - Optimizaci√≥n para Apple Silicon (NumPy/SciPy optimizado)
               - Procesamiento paralelo para escalabilidad

            üìã 2. Isolation Forest (implementaci√≥n de referencia) - SIGUIENTE PRIORIDAD

            üìã 3. Autoencoders (PyTorch/MPS para Apple SoC) - PRIORIDAD MEDIA

            üìã 4. One-Class SVM - PRIORIDAD BAJA

        Entrada: Semanas de referencia por celda (40,000 selecciones) + datos temporales

        Salida: Identificaci√≥n de puntos an√≥malos, scores de anomal√≠a por celda/tiempo
        
        Rendimiento Etapa 04 (OSP) - IMPLEMENTACI√ìN COMPLETA:
        
        Scripts Implementados:
        - scripts/04_anomaly_detection_osp.py: Detecci√≥n OSP principal
        - scripts/benchmark_osp_anomaly_detection.py: Framework de benchmarking
        
        Caracter√≠sticas T√©cnicas:
        - Modelado SVD per-celda con par√°metros configurables
        - Entrenamiento basado en semanas de referencia (Etapa 03)
        - Procesamiento paralelo optimizado para Apple Silicon
        - Manejo robusto de errores y validaci√≥n de datos
        - Soporte para datasets masivos (89M+ muestras)
        
        Rendimiento Dataset Completo (10,000 celdas - 100% coverage) - COMPLETADO:
        - ‚úÖ 100% tasa de √©xito (10,000/10,000 celdas procesadas)
        - ‚ö° 2,205,410 muestras/segundo throughput (15x mejor que proyecci√≥n)
        - üîß 247.1 celdas/segundo velocidad de procesamiento
        - üìä 89,245,318 muestras analizadas en 40.47 segundos
        - üéØ 5,561,393 anomal√≠as detectadas (6.23% tasa promedio)
        - üíæ 5.6GB uso de memoria (escalabilidad excelente)
        - üìÅ Archivos generados: 309MB detallado, 243KB resumen
        
        Hallazgos de Anomal√≠as:
        - üìà Rango de anomal√≠as: 0.00% - 49.08% por celda
        - üó∫Ô∏è Patrones geogr√°ficos: Celdas 5000s y 7000s muestran m√°s anomal√≠as
        - üìä Desviaci√≥n est√°ndar: ¬±5.55% entre celdas
        - üéØ Celdas m√°s an√≥malas: 5342 (49.1%), 5241 (49.0%), 5240 (48.4%)
        - ‚ú® Celdas normales: M√∫ltiples celdas con 0% anomal√≠as
        
        Configuraci√≥n √ìptima Determinada:
        - SVD Components: 3 (mejor balance throughput/precisi√≥n)
        - Anomaly Threshold: 2.0 desviaciones est√°ndar
        - Workers: 8 procesos paralelos
        - Standardization: Habilitada
        
        Framework de Benchmarking Automatizado:
        - Barrido param√©trico completo (quick/standard/extensive)
        - Monitoreo de recursos (CPU, memoria)
        - An√°lisis comparativo automatizado
        - Generaci√≥n de reportes markdown y visualizaciones
        - Exportaci√≥n de datos en JSON/CSV/Parquet
        
        Resultados de Benchmarking (quick mode - 9 configuraciones):
        - 66.7% tasa de √©xito general
        - Mejor throughput: 15,577 muestras/segundo
        - Tiempo promedio ejecuci√≥n: 7.2 segundos
        - Impacto de par√°metros cuantificado

    Evaluaci√≥n y Visualizaci√≥n de Anomal√≠as:

        Tarea: Implementar la visualizaci√≥n de las series temporales con anomal√≠as marcadas, distribuci√≥n de scores, etc.

        M√©tricas: Si se dispone de datos etiquetados (ground truth), calcular precisi√≥n, recall, F1-score. Si no, la evaluaci√≥n ser√° m√°s cualitativa.

    Benchmarking y Pruebas de Rendimiento en Apple SoC:

        Tarea: Dise√±ar y ejecutar scripts de benchmarking para cada etapa del pipeline (carga, reorganizaci√≥n, ingenier√≠a de caracter√≠sticas, detecci√≥n) tanto en SoC de Apple como en otras arquitecturas si es posible.

        M√©tricas Clave: Tiempo de ejecuci√≥n, uso de CPU/GPU/ANE, consumo energ√©tico (estimado).

        Herramientas: time.perf_counter(), cProfile, htop, asitop, Monitor de Actividad de macOS.

6. Consideraciones para el Agente CLI

    Manejo de Errores: Asegurar un manejo robusto de errores y logging detallado en todas las etapas.

    Modularidad: Mantener el c√≥digo modular para facilitar las pruebas y la modificaci√≥n de componentes individuales del pipeline.

    Eficiencia: Prestar atenci√≥n a la eficiencia en el uso de memoria y CPU, especialmente con Pandas en datasets grandes.

    Reproducibilidad: Usar semillas (random_state) en algoritmos estoc√°sticos.

    Documentaci√≥n: Comentar adecuadamente el c√≥digo y las decisiones de dise√±o.

Este contexto deber√≠a ayudar a un agente CLI a entender el estado actual y las direcciones futuras del proyecto.

8. Archivos de Documentaci√≥n Generados

    Reportes de Rendimiento:
        - reports/documentation/WEEK_SELECTION_PERFORMANCE.md: An√°lisis completo de rendimiento Etapa 03
        - reports/documentation/PERFORMANCE_LEVELS.md: Jerarqu√≠a de niveles de optimizaci√≥n
        - reports/documentation/PERFORMANCE_MEASUREMENTS.md: Mediciones detalladas
        - reports/documentation/INGESTION_PERFORMANCE_TUNING.md: Optimizaci√≥n de ingesta

    Scripts de Benchmarking:
        - scripts/benchmark_week_selection.py: Framework de pruebas param√©tricas para Etapa 03
        - scripts/benchmark_all_levels.py: Benchmarking de niveles de optimizaci√≥n
        - scripts/benchmark_osp_anomaly_detection.py: Benchmarking completo Etapa 04 OSP

    Scripts de Implementaci√≥n:
        - scripts/04_anomaly_detection_osp.py: Detecci√≥n de anomal√≠as OSP principal
        - scripts/benchmark_osp_anomaly_detection.py: Framework de benchmarking OSP
        
    Estado del Repositorio:
        - Estructura organizada con reports/ y documentation/
        - Control de versiones actualizado
        - Configuraci√≥n Apple Silicon optimizada
        - Pipeline completo de extremo a extremo funcional
        - Frameworks de benchmarking para todas las etapas
        - ‚úÖ BACKUP CREADO: edge_mobile_v1_20250620 (scripts/, reports/ respaldados)
        - backup/ directory agregado a .gitignore

7. Configuraci√≥n de Git

git_remote_origin=git@github.com:josemifv/Edge-Mobile-Anomaly-Detection-Apple.git

8. Configuraci√≥n CMMSE 2025

    Rama de Desarrollo: cmmse2025 (creada para publicaci√≥n acad√©mica)
    
    Nueva Estructura del Proyecto:
    
        src/edge_mobile_anomaly/: Paquete principal restructurado
        ‚îú‚îÄ‚îÄ core/: Funcionalidades centrales del framework
        ‚îú‚îÄ‚îÄ data/: M√≥dulos de gesti√≥n de datos
        ‚îú‚îÄ‚îÄ models/: Implementaciones de algoritmos de ML
        ‚îú‚îÄ‚îÄ utils/: Utilidades y helpers
        ‚îî‚îÄ‚îÄ visualization/: Herramientas de visualizaci√≥n
        
        tests/: Framework de pruebas
        ‚îú‚îÄ‚îÄ unit/: Pruebas unitarias
        ‚îî‚îÄ‚îÄ integration/: Pruebas de integraci√≥n
        
        config/: Configuraciones por entorno
        ‚îú‚îÄ‚îÄ development/: Configuraci√≥n de desarrollo
        ‚îî‚îÄ‚îÄ production/: Configuraci√≥n de producci√≥n
        
        docs/: Documentaci√≥n t√©cnica
        ‚îú‚îÄ‚îÄ api/: Documentaci√≥n de API
        ‚îî‚îÄ‚îÄ benchmarks/: Documentaci√≥n de benchmarks
        
        results/: Salidas del sistema
        ‚îú‚îÄ‚îÄ figures/: Gr√°ficos y visualizaciones
        ‚îî‚îÄ‚îÄ data/: Datos de resultados
    
    Archivos de Configuraci√≥n:
    
        .env.example: Plantilla de configuraci√≥n con valores por defecto
        - Configuraci√≥n de desarrollo (DEBUG=True)
        - Par√°metros de procesamiento (CHUNK_SIZE=100000, MAX_WORKERS=14)
        - Modo de rendimiento (PERFORMANCE_MODE=1)
        - Aceleraci√≥n de hardware (USE_MPS=True, MPS_FALLBACK=True)
        
        .env: Archivo de configuraci√≥n local (vac√≠o por defecto)
        
        .dockerignore: Exclusiones para contenedores Docker
        - backup/, .env, archivos cache, logs
    
    Estado del Commit:
    
        Commit: 5a54f0e - "feat: initialize new project structure for CMMSE 2025"
        - 41 archivos modificados
        - Nueva estructura de paquetes creada
        - Archivos de configuraci√≥n inicializados
        - Limpieza de archivos legacy de reportes
        
    Prop√≥sito: Preparaci√≥n para publicaci√≥n acad√©mica en CMMSE 2025 con estructura modular y configuraci√≥n optimizada para Apple Silicon.

9. Step 3 Completed: Project Metadata Updates

    Commit: bc48b70 - "chore: update project metadata for CMMSE 2025"
    
    Actualizaciones Realizadas:
    
        pyproject.toml:
        - Version actualizada a 0.2.0
        - Descripci√≥n espec√≠fica: "Mobile Network Anomaly Detection Pipeline Optimized for Apple Silicon"
        - Metadata completa: autor, licencia, readme, keywords
        - Keywords acad√©micas: anomaly-detection, mobile-networks, apple-silicon, machine-learning
        - Dependencia torch>=2.2.0 a√±adida (soporte MPS)
        - Dependencia python-dotenv>=1.0.0 a√±adida
        - Configuraci√≥n completa dev dependencies (pytest, black, isort, mypy)
        - Build system con hatchling
        - Configuraci√≥n de herramientas (pytest, black, isort)
        
        README.md:
        - Enfoque CMMSE 2025 conference
        - Instalaci√≥n con uv tool
        - Configuraci√≥n .env
        - Estado de desarrollo acad√©mico
        - Eliminaci√≥n del contenido legacy t√©cnico
        
    Cambios:
    - 2 archivos modificados
    - 60 inserciones, 264 eliminaciones
    - Estructura lista para publicaci√≥n acad√©mica
