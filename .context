Edge-Mobile Anomaly Detection Apple - Project Context
====================================================

1. PROJECT OVERVIEW
==================

Project: Mobile Network Anomaly Detection Pipeline Optimized for Apple Silicon
Purpose: Academic research for CMMSE 2025 conference submission
Repository: https://github.com/josemifv/Edge-Mobile-Anomaly-Detection-Apple.git
Branch: cmmse2025 (current development branch)
Python Version: 3.13.2 (managed with uv tool)

Academic Focus:
- Enhanced mobile network anomaly detection pipeline
- Hardware optimization for Apple Silicon (M-series processors) 
- OSP (Orthogonal Subspace Projection) based anomaly detection
- Research-grade implementation with reproducible results

2. CURRENT REPOSITORY STRUCTURE
===============================

Edge-Mobile-Anomaly-Detection-Apple/
├── .git/                          # Git version control
├── .gitignore                     # Git ignore patterns
├── .python-version                # Python 3.13 specification
├── .venv/                         # Virtual environment (uv-managed)
├── LICENSE                        # MIT License (José Miguel Franco-Valiente)
├── README.md                      # Complete project documentation
├── requirements.txt               # Python dependencies
├── backup/                        # Backup directory (git-ignored)
├── data/                          # Data storage
│   ├── raw@ -> ../../datasets/milan_telecom/raw  # Symlink to raw data
│   └── processed/                 # Processed data files
│       ├── ingested_data.parquet     # Stage 1 output (4.4GB, 319.9M rows)
│       ├── preprocessed_data.parquet # Stage 2 output (2.0GB, 89.2M rows)
│       └── reference_weeks.parquet   # Stage 3 output (479KB, 39.4K refs)
├── results/                       # Analysis outputs and results
│   ├── anomalies.parquet             # Standard anomaly detection results
│   ├── full_individual_anomalies.parquet  # Individual anomaly records (148MB)
│   ├── severe_anomalies_top_*.csv    # Severity analysis reports
│   ├── figures/                      # Visualization outputs
│   ├── benchmarks/                   # Performance benchmark results
│   └── data/                         # Micro test results by configuration
└── scripts/                       # Core pipeline implementation (9 scripts)
    ├── 01_data_ingestion.py             # Stage 1: Data loading & preprocessing
    ├── 02_data_preprocessing.py         # Stage 2: Aggregation & validation
    ├── 03_week_selection.py             # Stage 3: Reference week selection
    ├── 04_anomaly_detection_osp.py      # Stage 4: OSP anomaly detection
    ├── 04_anomaly_detection_osp_detailed.py  # Enhanced individual tracking
    ├── analyze_severe_anomalies.py      # Severity analysis tools
    ├── benchmark_parameter_sweep.py     # Comprehensive parameter optimization
    ├── benchmark_micro_test.py          # Quick system validation
    └── run_pipeline.py                  # Complete pipeline orchestrator

3. CORE PIPELINE ARCHITECTURE (4 STAGES)
========================================

Stage 1: Data Ingestion (01_data_ingestion.py)
- Input: Raw .txt files from Milano Telecom dataset
- Processing: Parallel file loading optimized for Apple Silicon
- Features: Timestamp conversion, column standardization, data type optimization
- Output: ingested_data.parquet (319.9M rows, 4.4GB)
- Performance: 1.77M rows/second (181.02s execution)

Stage 2: Data Preprocessing (02_data_preprocessing.py)
- Input: Ingested data from Stage 1
- Processing: Cell-wise aggregation, directional column merging, validation
- Features: SMS/call consolidation, quality checks, 72% data compression
- Output: preprocessed_data.parquet (89.2M rows, 2.0GB)
- Performance: 564K rows/second (159.17s execution)

Stage 3: Reference Week Selection (03_week_selection.py)
- Input: Preprocessed data from Stage 2
- Processing: MAD (Median Absolute Deviation) analysis for normal week identification
- Features: ISO week numbering, statistical outlier detection, configurable thresholds
- Output: reference_weeks.parquet (39.4K reference weeks)
- Performance: 795K rows/second (112.27s execution)

Stage 4: OSP Anomaly Detection (04_anomaly_detection_osp.py)
- Input: Preprocessed data + reference weeks from Stages 2 & 3
- Processing: Orthogonal Subspace Projection with SVD decomposition
- Features: Per-cell modeling, parallel processing, configurable parameters
- Output: anomalies.parquet (5.65M anomalies detected, 6.33% rate)
- Performance: 190K samples/second (469.97s execution)

4. ALGORITHM IMPLEMENTATION
==========================

OSP (Orthogonal Subspace Projection) Anomaly Detection:
- Mathematical foundation: SVD decomposition X = UΣV^T
- Normal subspace projection with reconstruction error calculation
- Anomaly scoring: ||residuals||_2 compared to threshold
- Per-cell training using reference weeks from Stage 3
- Configurable parameters:
  * n_components: SVD dimensions (default: 3)
  * anomaly_threshold: Standard deviation multiplier (default: 2.0)
  * standardize: Feature standardization (default: True)

Enhanced Individual Tracking (04_anomaly_detection_osp_detailed.py):
- Individual anomaly record capture with timestamps
- Severity scoring: (anomaly_score - training_mean) / training_std
- Traffic feature preservation for analysis
- Excess factor calculation (threshold multiples)

5. PERFORMANCE ACHIEVEMENTS (Apple Silicon M4 Pro)
==================================================

Dataset: Milano Telecom (62 files, 319.9M rows, Nov 2013 - Jan 2014)

Pipeline Performance:
- Stage 1: 181.02s | 1.77M rows/sec | 319.9M → 319.9M rows
- Stage 2: 159.17s | 564K rows/sec | 319.9M → 89.2M rows (72% compression)
- Stage 3: 112.27s | 795K rows/sec | 39.4K reference weeks selected
- Stage 4: 469.97s | 190K samples/sec | 5.65M anomalies (6.33% rate)
- Total: 922.43s (15.37 minutes) | 347K rows/sec overall

Key Metrics:
- Success rate: 100% (10,000/10,000 cells processed)
- Data compression: 72% through aggregation
- Anomaly detection rate: 6.33% average across all cells
- Memory efficiency: 5.6GB peak usage
- Reference weeks: 39.4K selected (≈4 per cell average)

Anomaly Severity Analysis:
- Severity range: 2.0σ to 5,717σ (standard deviations above normal)
- Most severe cell: 5240 (multiple extreme anomalies)
- Peak anomaly patterns: Night hours (01:00-02:00), weekdays
- Traffic characteristics: High call volumes without proportional SMS/internet

6. APPLE SILICON OPTIMIZATIONS
==============================

Hardware Acceleration:
- Native ARM64 compilation (aarch64 architecture)
- PyTorch MPS (Metal Performance Shaders) support enabled
- Automatic CPU core detection and utilization
- Optimized multiprocessing for M-series processors

Software Optimizations:
- NumPy/SciPy ARM64 optimized versions
- scikit-learn Apple Silicon compilation
- Parallel processing strategies for file I/O and computation
- Memory-efficient data structures and operations

Configuration:
- Default workers: Auto-detected (8-14 for M-series)
- Virtual environment: Python 3.13.2 with uv package manager
- Dependencies: All Apple Silicon native packages

7. DEVELOPMENT TOOLS & ENVIRONMENT
==================================

Python Environment:
- Python 3.13.2 (specified in .python-version)
- Package manager: uv 0.6.14 (Astral's fast tool)
- Virtual environment: .venv/ (properly isolated)
- Dependencies: requirements.txt (traditional approach for academic simplicity)

Core Dependencies:
- pandas ≥2.3.0 (data processing)
- numpy ≥2.2.6 (numerical computing)
- pyarrow ≥20.0.0 (parquet I/O)
- scikit-learn ≥1.7.0 (machine learning)
- torch ≥2.2.0 (MPS support for Apple Silicon)
- matplotlib ≥3.10.3, seaborn ≥0.13.2 (visualization)
- psutil ≥7.0.0 (system monitoring)

Development Tools:
- pytest ≥8.0.0 (testing framework)
- black ≥24.1.0 (code formatting)
- isort ≥5.13.0 (import sorting)

8. ACADEMIC RESEARCH FEATURES
=============================

CMMSE 2025 Conference Focus:
- Clean, documented code structure for academic publication
- Reproducible results with parameter control
- Comprehensive performance benchmarking
- Individual anomaly analysis capabilities

Research Tools:
- Parameter sweep framework (benchmark_parameter_sweep.py)
- Quick validation testing (benchmark_micro_test.py)
- Severity analysis with visualizations (analyze_severe_anomalies.py)
- Individual anomaly tracking for case studies

Documentation:
- Complete README with usage examples
- Inline code documentation and academic comments
- Performance results and configuration tables
- Research-grade implementation standards

9. CURRENT PROJECT STATUS
=========================

Development Branch: cmmse2025
Last Commit: eee6bcb - "docs: finalize CMMSE 2025 refactor documentation"

Completed Components:
✅ Core 4-stage pipeline fully implemented and tested
✅ Apple Silicon optimization verified and documented
✅ Complete dataset processing (100% success rate)
✅ Individual anomaly analysis framework
✅ Comprehensive benchmarking tools
✅ Academic documentation for CMMSE 2025
✅ Clean repository structure with minimal dependencies

Testing Status:
✅ End-to-end pipeline verification completed
✅ Performance benchmarking on full dataset
✅ Individual anomaly analysis validated
✅ Micro testing framework operational

Repository Health:
✅ Clean commit history with academic focus
✅ Proper dependency management with uv
✅ Data directories excluded from version control
✅ Backup system implemented
✅ Documentation complete and current

10. USAGE EXAMPLES
==================

Individual Stage Execution:
```bash
# Stage 1: Data Ingestion
python scripts/01_data_ingestion.py data/raw/ --output_path data/processed/ingested_data.parquet

# Stage 2: Data Preprocessing  
python scripts/02_data_preprocessing.py data/processed/ingested_data.parquet --output_path data/processed/preprocessed_data.parquet

# Stage 3: Reference Week Selection
python scripts/03_week_selection.py data/processed/preprocessed_data.parquet --output_path data/processed/reference_weeks.parquet

# Stage 4: OSP Anomaly Detection
python scripts/04_anomaly_detection_osp.py data/processed/preprocessed_data.parquet data/processed/reference_weeks.parquet --output_path results/anomalies.parquet
```

Complete Pipeline:
```bash
# Run complete 4-stage pipeline
python scripts/run_pipeline.py data/raw/ --output_dir results/

# With custom parameters
python scripts/run_pipeline.py data/raw/ --output_dir results/ --n_components 5 --anomaly_threshold 2.5 --preview
```

Enhanced Analysis:
```bash
# Generate individual anomaly data
python scripts/04_anomaly_detection_osp_detailed.py data/processed/preprocessed_data.parquet data/processed/reference_weeks.parquet --individual_output_path results/full_individual_anomalies.parquet

# Analyze severe anomalies
python scripts/analyze_severe_anomalies.py results/full_individual_anomalies.parquet --top_n 20 --generate_plots --export_report
```

11. NEXT RESEARCH DIRECTIONS
============================

Potential Extensions:
- Additional anomaly detection algorithms (Isolation Forest, Autoencoders)
- Time series feature engineering enhancements
- Spatial correlation analysis between cells
- Real-time anomaly detection capabilities
- Comparative studies with other hardware architectures

Academic Applications:
- Network incident investigation frameworks
- Capacity planning optimization
- Security monitoring for telecom networks
- Quality of service enhancement strategies

Publication Ready:
- Code structure optimized for academic review
- Comprehensive documentation and examples
- Reproducible results with clear methodology
- Performance benchmarks for Apple Silicon architecture

==========================================
Status: ✅ COMPLETE - CMMSE 2025 Ready
Last Updated: June 21, 2025
==========================================
